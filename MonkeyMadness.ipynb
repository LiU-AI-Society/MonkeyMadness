{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonkeyMadness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Enable GPU & SETUP ENVIROMENT\n",
    "#### Deep learning algorithms are computationally intensive, and using a GPU can significantly reduce training times. Follow these steps to enable GPU acceleration:\n",
    "##### Enabling GPU in Google Colab (Recomended)\n",
    "1. Navigate to the top menu and click on \"Runtime\"\n",
    "2. Select \"Change runtime type\"\n",
    "3. In the dialog box: \n",
    "    - Choose the appropriate runtime type (typically Python 3)\n",
    "    - Set the \"Hardware accelerator\" to \"GPU\"\n",
    "    - A Tesla T4 GPU is typically available for free users\n",
    "4. Click \"Save\" to apply the changes\n",
    "#### Local Machine Setup \n",
    "- M1 chip or later (mac)\n",
    "- CUDA already installed (Windows/Linux)\n",
    "- Make sure to install req_local.txt in code block 2 \"Setup Environment\"\n",
    "##### Performance: 30 epochs take ~20 minutes on T4 and might be faster on your own gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #if os not available, add pip install \n",
    "import torch #if not available on local, add !pip install torch before\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "# Check if already in MonkeyMadness directory\n",
    "if current_dir.endswith('MonkeyMadness'): #prevent nested cloning of repo\n",
    "    print(\"✅ Already in MonkeyMadness directory, no need to clone again ✅\")\n",
    "else:\n",
    "    # Safe cloning if not in the directory\n",
    "    !git clone https://github.com/LiU-AI-Society/MonkeyMadness.git\n",
    "    HOME = os.getcwd()\n",
    "    print(f\"Current working directory: {HOME}\")\n",
    "    %cd {HOME}/MonkeyMadness\n",
    "\n",
    "    %pip install -r req_colab.txt  # Change to req_local.txt if on local machine, done with python version 3.12.1. make sure to restart the kernel after\n",
    "\n",
    "\n",
    "from get_device import DeviceManager\n",
    "\n",
    "# Get the device\n",
    "device = DeviceManager.get_device()\n",
    "\n",
    "# Print detailed device information\n",
    "DeviceManager.print_device_info(device)\n",
    "\n",
    "# Optional additional checks\n",
    "if device.type == 'cuda':\n",
    "    !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CONVOLUTION BLOCK\n",
    "\n",
    "This is just to get a feeling of the convolutional operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from convolution import perform_convolution, plot_images\n",
    "\n",
    "# Load the image\n",
    "image_path = 'Monkey/training/training/n7/n7023.jpg'\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Transform the image to a tensor\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Define vertical and horizontal line detection kernels\n",
    "vertical_line_kernel = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                     [-1.0, 0.0, 1.0],\n",
    "                                     [-1.0, 0.0, 1.0]], dtype=torch.float32)\n",
    "\n",
    "horizontal_line_kernel = torch.tensor([[-1.0, -1.0, -1.0],\n",
    "                                       [0.0,  0.0,  0.0],\n",
    "                                       [1.0,  1.0,  1.0]], dtype=torch.float32)\n",
    "\n",
    "# Perform the convolutions\n",
    "horizontal_lines_image = perform_convolution(horizontal_line_kernel, image)\n",
    "vertical_line_image = perform_convolution(vertical_line_kernel, image)\n",
    "\n",
    "# plot the result\n",
    "\n",
    "plot_images(image, vertical_line_image, horizontal_lines_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATASET BLOCK\n",
    "### You will use a monkey dataset consisting of ca 1000 images of monkey. The goal is to be able to classify them.\n",
    "### There are ten monkey classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "from Dataset import CustomImageDataset, MonkeyImageDataset\n",
    "\n",
    "NUM_OF_CLASSES = 10\n",
    "IMAGE_SIZE = (64, 64) # DO NOT ALTER THIS PARAMETER\n",
    "\n",
    "DATA_PERCENTAGE = 0.5\n",
    "transform = transforms.Compose([\n",
    "    #Randomly flip the images vertically\n",
    "    #transforms.RandomVerticalFlip(p=0.2),  # Randomly flip the image vertically with 20% probability\n",
    "    #transforms.RandomHorizontalFlip(p=0.2),  # Randomly flip the image horizontally with 20% probability\n",
    "    #transforms.RandomRotation(degrees=15),  # Rotate the image randomly within a 15-degree range\n",
    "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly change brightness, contrast, etc.\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE[0], IMAGE_SIZE[1])), \n",
    "\n",
    "    #for imagenet\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset = MonkeyImageDataset('Monkey/training/training', transform, NUM_OF_CLASSES, data_percentage = DATA_PERCENTAGE )\n",
    "dataset.visualize(5)\n",
    "#dataset.visualize_all_classes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MODEL BLOCK\n",
    "## Let's define our model! \n",
    "### Lets build a Convolutional Neural Network (CNN). It uses convolutions (one can think of it as filters) to learn the different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL CODE BLOCK\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class MonkeyNET(nn.Module):\n",
    "    def __init__(self, num_classes=10, input_size=(500, 500)):\n",
    "        super(MonkeyNET, self).__init__()\n",
    "\n",
    "        # First convolutional layer: 3 input channels (RGB),  output channels, kernel size 5, padding 2 to preserve size\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, padding=1)\n",
    "        # Calculate the size of the fully connected layer dynamically\n",
    "        self.fc_input_size = self._get_fc_input_size(input_size)\n",
    "        self.fc = nn.Linear(self.fc_input_size, num_classes) # Adjusted for the final size after pooling\n",
    "\n",
    "\n",
    "    def _get_fc_input_size(self, input_size):\n",
    "        x = torch.zeros(1, 3, *input_size) # Create a dummy input tensor\n",
    "        #x = self.attention(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=(4, 4), stride=4)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=(8, 8), stride=8)\n",
    "\n",
    "\n",
    "        return x.numel() # Total number of elements after conv layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First conv -> ReLU -> Max Pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=(4, 4), stride=4)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = F.max_pool2d(x, kernel_size=(8, 8), stride=8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Flatten the tensor for fully connected layer\n",
    "        x = x.view(x.size(0), -1) \n",
    "\n",
    "        # Fully connected layer -> ReLU\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = MonkeyNET(num_classes=NUM_OF_CLASSES, input_size=IMAGE_SIZE).to(device) #delete .to(device) if m1\n",
    "\n",
    "summary(model, (3, IMAGE_SIZE[0], IMAGE_SIZE[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TRAINING BLOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train, training_info\n",
    "from test_model import test\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import datetime\n",
    "from GradCam import GradCAM, generate_and_save_grad_cams\n",
    "import numpy as np\n",
    "current_datetime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 40 # how long should the model train\n",
    "MODEL_NAME = \"groupname and what you are testing\"  #name for the training run to be able to compare\n",
    "\n",
    "\n",
    "ID = f\"{current_datetime.hour:02}:{current_datetime.minute:02}\"\n",
    "LR = 0.01   # how \"much\" should the model learn\n",
    "BATCH_SIZE = 8  # how many images should the model see before updating\n",
    "\n",
    "model_info = {\n",
    "            'epochs' : EPOCHS,\n",
    "            'batch_size' : BATCH_SIZE,\n",
    "            'lr' : LR,\n",
    "            'ID' : ID,\n",
    "            'model_name' : MODEL_NAME\n",
    "}\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)  # 80% for training\n",
    "val_size = dataset_size - train_size   # 20% for validation\n",
    "criterion = nn.CrossEntropyLoss() #This is the loss function\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = MonkeyNET(num_classes=NUM_OF_CLASSES, input_size=IMAGE_SIZE)\n",
    "\n",
    "# Create optimizers for the model. This will try to find the optimal parameters in the model i.e this adjusts the model to improve the loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "# Move models to gpu and train \n",
    "model.to(device)\n",
    "model, t_loss, t_acc, v_loss, v_acc = train(model, train_loader, val_loader, optimizer, criterion, device, start_epoch=0, num_epochs=EPOCHS, model_name=MODEL_NAME, unique_id=ID)\n",
    "\n",
    "\n",
    "model_info['t_loss'] = t_loss\n",
    "model_info['t_acc'] = t_acc\n",
    "\n",
    "model_info['v_loss'] = v_loss\n",
    "model_info['v_acc'] = v_acc\n",
    "\n",
    "training_info(model_info=model_info)\n",
    "\n",
    "# see metrics on the validation set\n",
    "\n",
    "acc = test(model=model, testloader=val_loader, device=device, model_name=MODEL_NAME, unique_id=ID)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.GradCAM block: The red parts are what the model \"looks\" at for making it's prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-AI block\n",
    "\n",
    "common_names = [\n",
    "    \"mantled_howler\",\n",
    "    \"patas_monkey\",\n",
    "    \"bald_uakari\",\n",
    "    \"japanese_macaque\",\n",
    "    \"pygmy_marmoset\",\n",
    "    \"white_headed_capuchin\",\n",
    "    \"silvery_marmoset\",\n",
    "    \"common_squirrel_monkey\",\n",
    "    \"black_headed_night_monkey\",\n",
    "    \"nilgiri_langur\"\n",
    "]\n",
    "\n",
    "\n",
    "grad_cam = GradCAM(model=model, target_layer=model.conv2) # change target layer to the last conv layer if you add more\n",
    "\n",
    "generate_and_save_grad_cams(model, grad_cam, val_loader, common_names, save_dir=\"grads\", device=device, index=np.random.randint(len(val_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 COMPARING BLOCK\n",
    "## See all performed experiments in graph to compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from train import plot_experiments\n",
    "\n",
    "plot_experiments('training_metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send your best model to us for us to run it on a test set!\n",
    "\n",
    "## Upload to google drive folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vis_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
